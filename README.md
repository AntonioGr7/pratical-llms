# Guide for LLM Practitioners

Welcome to the repository for LLM (Large Language Model) engineers! This collection of Jupyter Notebooks is designed to collect pratical aspects of our job. 
I will collect and add jupyter and/or script for learning and experimenting purpose. 

## Notebooks Included

1. `1_understanding_llms_benchmarks.ipynb`: This notebook provides an explanation of the main benchmarks used in the openLLM leaderboard. It aims to help you grasp the key metrics and methodologies used in benchmarking LLMs.


2. `2_quantization_base.ipynb`: In this notebook, you'll learn how to open a Hugging Face model in 8-bit and 4-bit using the BitandBytes library. Quantization is a crucial technique for optimizing model performance and resource usage, and this notebook guides you through the process.

3. `3_quantization_gptq.ipynb`: Explore quantization in GPTQ format using the auto-gptq library with this notebook. GPTQ format is gaining popularity for its effectiveness in compressing and quantizing large models like GPT. Learn how to leverage this format for your models.

## Additional Resources

For further resources and support, feel free to reach out to the community or refer to the following:

- [BitandBytes GitHub Repository](https://github.com/TimDettmers/bitsandbytes): Learn more about the BitandBytes library for quantization.
- [Auto-GPTQ GitHub Repository](https://github.com/AutoGPTQ/AutoGPTQ): Access the auto-gptq library for GPTQ format quantization.
- [ExLlamaV2 GitHub Repository](https://github.com/turboderp/exllamav2): Learn more about the ExLlamaV2 library for quantization and fast inference.


Happy learning and experimenting with LLMs! ðŸš€
